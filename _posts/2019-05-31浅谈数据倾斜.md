
龙
## 浅谈数据倾斜

#### 数据倾斜：
Shuffle阶段的优化过程，遇到数据倾斜的问题，造成了对一些情况优化效果不明显。主要是因为job完成后的所得到的Counters是整个job的总和，优化是基于这些Counters得出的平均值，而由于数据倾斜的原因造成map处理数据量的差异过大，使得这些平均值能代表的价值降低。
```
Hive的执行是分阶段的，map处理数据量的差异取决于上一个stage的reduce输出，
所以如何将数据均匀的分配到各个reduce中，就是解决数据倾斜的根本所在。规避
错误来更好的运行比解决错误更高效。
```


#### 原因：

join
1. 其中一个表比较小但是key集中，这个key 分发到与之对应的reduce的数据远高于平均值，发生数据倾斜
2. 大小表问题，但是其中的字段0值或空值过多，最后这些空值也都会由一个reduce处理，就非常慢
3. group by，某一个值的数据量过多，count（distinct ）中特殊值过多。
```
1)  key值分布不均
2)  业务数据本身的原因
3)  创建表时考虑不周
4)  某些SQL运用不当，或者SQL 本身就数据倾斜
```

#### 任务表现：

任务进度长时间维持在99% 或者100% 状态（但是没有运行结束的意思）查看任务监控页面，发现只有少量（1个或几个）reduce子任务未完成。因为其处理的数据量和其他reduce差异过大。


#### 一些解决方案：

1. 参数调整
hive.map.aggr = true 
可以在map端有聚合操作
hive.groupby.skewindata=true
数据倾斜的时候进行负载均衡，当项设定为 true，生成的查询计划会有两个 MR Job。第一个 MR Job 中，Map 的输出结果集合会随机分布到 Reduce 中，每个 Reduce 做部分聚合操作，并输出结果，这样处理的结果是相同的 Group By Key 有可能被分发到不同的 Reduce 中，从而达到负载均衡的目的；第二个 MR Job 再根据预处理的数据结果按照 Group By Key 分布到 Reduce 中（这个过程可以保证相同的 Group By Key 被分布到同一个 Reduce 中），最后完成最终的聚合操作。相当于两次mapreduce操作
2. SQL语句调整
关于驱动表的取，用join key分布最均匀的表作为驱动表
做好列裁剪和filter操作，以达到两表做join的时候，数据量相对变小的效果。
大小表Join：
使用map join让小的维度表（1000条以下的记录条数） 先进内存。在map端完成reduce.
大表Join大表：
把空值的key变成一个字符串加上随机数，把倾斜的数据分到不同的reduce上，由于null值关联不上，处理后并不影响最终结果。
count distinct大量相同特殊值
count distinct时，将值为空的情况单独处理，如果是计算count distinct，可以不用处理，直接过滤，在最后结果中加1。如果还有其他计算，需要进行group by，可以先将值为空的记录单独处理，再和其他计算结果进行union。
group by维度过小：
采用sum() group by的方式来替换count(distinct)完成计算。
特殊情况特殊处理：
在业务逻辑优化效果的不大情况下，一些时候是可以将倾斜的数据单独拿出来处理。最后union回去。


3. 
